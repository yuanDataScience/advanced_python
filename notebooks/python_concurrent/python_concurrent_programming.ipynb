{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77688c28",
   "metadata": {},
   "source": [
    "### This notebook is from a linkedin class on python concurrent programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52a0eff",
   "metadata": {},
   "source": [
    "### sequential/serial execution\n",
    "* program execute a series of instructions sequentially\n",
    "* one instruction is executed at any give moment\n",
    "* speed of the pogram is limited by cpu and how fast it can execute that series of instructions\n",
    "\n",
    "### parallel programming\n",
    "* with multiple processes, the instructions can be broken down into independent parts and executed simultaneously by different processes\n",
    "* components that depend on all parts need the coordinations between the different parts.\n",
    "* extra complexity is added to coordinate the actions, so the processing speed is not linear with the number of processors.\n",
    "* parallel execution increases throughput by\n",
    "  * accomplish a single task faster\n",
    "  * accomplish more tasks in a given time\n",
    "  * scale of the problem that can solve. Big computational tasks have to rely on parallel programming to save time, which outweights the cost of added hardware \n",
    "  \n",
    "### multiprocessor architectures\n",
    "* Flynn's taxonomy (4 classes of computer architecture based on number of concurrent instruction/control streams and number of data streams\n",
    "  * SISD (single instruction single data)\n",
    "    + sequential computer with a single processor unit\n",
    "    + one single instruction at any given moment\n",
    "  * SIMD (single instruction multiple data)  \n",
    "    + parallel computer with multiple processor units\n",
    "    + execute the same instructions at any give momonet, but can operate on different data element\n",
    "    + for example, both executing chopping, one on onion, one on carrot, and their operations are in sync\n",
    "    + suitable for applications that perform the same handful of operations on a massive set of data elements, such as in image analysis. modern computers use GPU with SIMD instructions to do that\n",
    "  * MISD (mutiple instruction, single data)\n",
    "    + each processor unit independently execute its own separate series of instructions, but all of them are operating on the single stream of data.\n",
    "    + not a commonly used architecture\n",
    "  * MIMD (multiple instruction, multiple data)\n",
    "    + multiple processor units. Every processor unit can process a different series of instructions\n",
    "    + at the same time, each of those processors can be operating on a different set of data\n",
    "    + most commonly used architecture in Flynn's taxonomy from multiple core pcs to network clusters in supercomputers.\n",
    "    + separated further into two parallel programming models:\n",
    "      + SPMD (single program, multiple data)\n",
    "        + multiple porcessing units excute a copy of the same single program simultaneously.\n",
    "        + they can each use a different data.\n",
    "        + different from SIMD since in SIMD, processing units execute the same instruction at the same time. In SPMD, procssing units just execute the same program\n",
    "        + the processes can run asynchronously and the program usually includes conditional logic that allows different tasks of the program to only execute the specific parts of the program\n",
    "        + example, two processors execute the same recipe, but can execute the different parts of the recipe\n",
    "        + most common of parallel programming. using multiple processor computer to execute the same program as a MIMD architecture\n",
    "      + MPMD (multiple program, multiple data)\n",
    "        + Each processing unit is processing a different program.\n",
    "        + processors execute indepently on different programs and may on different data. (a head/manager nodes with many worker nodes for function decomposition)\n",
    "* another aspect to conside to categorize computer architectures is based on how memory is organized and how computer access data\n",
    "  + memory opertes at a speed that is usually slower than processor speed.\n",
    "  + when one processor is reading or writing to memory, it only prevents other processors to access that same memory element\n",
    "  + two main memory architecures for parallel computing\n",
    "    + shared memory\n",
    "      + all processors access the same memory with global address space. Although each processor executes its own instructions independently, if one process changes a memory loaction, all the processors will see the change.\n",
    "      + this doesn't mean all the data are on the same physical device. It could be spread across a cluster of systems. The key is all processors see everything happens in the shared memory space.\n",
    "      + shared memory architectures have two categories based on how processors are connected to memory and how fast they can access the memory\n",
    "      + easier to programming since it is easy to access data in shared memory\n",
    "      + difficult to scale since adding more processors to a shared memory system increases the traffic on the shared memory bus and cost to main the cache coherency with communications between all the parts.\n",
    "      + programmer is responsible to synchronize memory accesses to ensure correct behavior.\n",
    "        + uniform memory access (UMA)\n",
    "          + all processors have equal access to the memory and they can access it equally fast.\n",
    "          + Symmetric multiprocessing system (SMP) is a typical UMA architecture.\n",
    "            + two or more identical processor connected to a single shared memory through a system bus (processors connect to cache memory, which connects to system bus, which connects to manin memory, all connections are bi-directional)\n",
    "            + each of processor core of computer or mobile phone is treated as a separate processor as a SMP architecture.\n",
    "              + each core has its own cache as a small, very fast piece of memory that only it can see. The core uses it to store data it frequently works with.\n",
    "              + the challenge is that if a processor copies a copy of data from shared memory and changes it in its local cache, the change needs to be updated back in the shared memory before another processor reads the old value. This issue is called cache coherency. It is handled by the hardware in multicore processors \n",
    "        + nonuniform memory access (NUMA)\n",
    "          + physically connect multiple SMP systems (which is a UMA type architecture) together. The access is non-uniform because some processors will have quicker access to certain parts of the memory than others. (these SMP systems are connected by system bus, and are located on different positions of system bus. It takes longer to access the memory through the bus compared to shared memory within the same SMP). Overall, every processor can still see everything in memory.\n",
    "    + distributed memory\n",
    "      + each processor has its own memory with its own address space and there is no global address space. All processors are connected through some sort of network (such as an ethernet).\n",
    "      + each processor operates independently. if it makes changes to its local memory, that change is not automatically reflected in the memory of other processors. \n",
    "      + it is up to programmer to explicitly define how and when data is communicated between the nodes. (difficult)\n",
    "      + advantage of NUMA is it is scalable\n",
    "        + adding more processors to the system, you get more memory. This makes it cost-effective to use commodity, off-the-shelf computers and network equipment to build large distributed memory systems. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be9955b",
   "metadata": {},
   "source": [
    "### Threads and processes\n",
    "* process:\n",
    "  + when a computer runs an application, that instance of the program executing is referred to as a process\n",
    "    + includes code, data, and state information\n",
    "    + independent instance of a running program\n",
    "    + has its own, separate memory address and space\n",
    "    + can have hundreds of processes at the same time and an operating system's job is to manage all of them\n",
    "    + sharing resouces between processes will need to use inter-process communication(IPC)\n",
    "      + sockets and pipes\n",
    "      + shared memory\n",
    "      + remote procedure calls\n",
    "* within each process, there are one or more smaller sub-elements called threads\n",
    "  + each thread is an independent path of execution through the program\n",
    "  + a different sequence of instructions\n",
    "  + only exists as part of a process (subset of a process)\n",
    "  + basic unit that os manages. Os schedules threads for execution and allocates time on the processor to execute them.\n",
    "  + threads of the same process share the process's address space so they can access to the same resources and memory, including code varialbes, and data, making it easy to work together.\n",
    "  + sharing resources between processes is not as easy as sharing between threads in the same process.\n",
    "  + threads are light-weight and require less overhead to create and terminate\n",
    "  + operation system can switch between threads faster than processes  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c039ded",
   "metadata": {},
   "source": [
    "### concurrency and parallel execution\n",
    "* concurrency: ability of a program to be broken into parts that can be run indepently of each other. These parts can be executed out of order or partially out of order without impacting the result.\n",
    "* independent tasks without multiple processors will be executed by switching back and forth between them, but only one task can be executed at a moment. This may give an illustion of parallel execution, but it is just concurrent execution since only one task is executed at a moment.\n",
    "  + with multiple hardware, such as multiple processors, multiple tasks can be executed simultaneously, then we have parallel execution\n",
    "* concurrency refers to the program structure that enables to deal with multiple things at once\n",
    "* parallelism refers to siumultaneous execution that actually doing multiple things at once\n",
    "* concurrent programming is useful for I/O dependent tasks. when a thread is waiting for I/O response, we can use another thread to accept user's input.\n",
    "* parallel processing is useful for computational intensive tasks, such as matrix multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa55e00f",
   "metadata": {},
   "source": [
    "### concurrent python thread\n",
    "* using threads to handle concurrent tasks in python is straightforward.\n",
    "* pyhton interpreter will not allow concurrent threads to execute simultaneously and parallel due to GIL (global interpreter lock)\n",
    "* Global interpreter lock is a mechanism that limits python to only execute one thread at a time when CPython is used as the interpreter\n",
    "* GIL provide a simple way to provide thread-safe memory management for thread-safe operations.\n",
    "* multi-thread is still useful for many I/O bound applications since GIL will not lock threads\n",
    "* for CPU-bound applications, such as intensive computational tasks, GIL can negatively impact performance. \n",
    "  + we can implement parallel algorithms as external library functions such as C++ called by python functions.\n",
    "  + you can also use python multiprocessing package to use multiple processors instead of multiple threads.\n",
    "    + each process will have its a separate interpreter with its own GIL, so different processors can execute simultaneously\n",
    "    + communcations between processors are more difficult than between threads\n",
    "    + uses more resources compared to creating multiple threads\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "302a9446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Process ID:  10944\n",
      "Thread Count:  6\n",
      "<_MainThread(MainThread, started 6764)>\n",
      "<Thread(IOPub, started daemon 7740)>\n",
      "<Heartbeat(Heartbeat, started daemon 1356)>\n",
      "<ControlThread(Control, started daemon 8664)>\n",
      "<HistorySavingThread(IPythonHistorySavingThread, started 10936)>\n",
      "<ParentPollerWindows(Thread-4, started daemon 2876)>\n",
      "\n",
      "Starting 12 CPU Wasters...\n",
      "\n",
      "  Process ID:  10944\n",
      "Thread Count:  18\n",
      "<_MainThread(MainThread, started 6764)>\n",
      "<Thread(IOPub, started daemon 7740)>\n",
      "<Heartbeat(Heartbeat, started daemon 1356)>\n",
      "<ControlThread(Control, started daemon 8664)>\n",
      "<HistorySavingThread(IPythonHistorySavingThread, started 10936)>\n",
      "<ParentPollerWindows(Thread-4, started daemon 2876)>\n",
      "<Thread(Thread-5 (cpu_waster), started 3156)>\n",
      "<Thread(Thread-6 (cpu_waster), started 10548)>\n",
      "<Thread(Thread-7 (cpu_waster), started 7372)>\n",
      "<Thread(Thread-8 (cpu_waster), started 7884)>\n",
      "<Thread(Thread-9 (cpu_waster), started 6424)>\n",
      "<Thread(Thread-10 (cpu_waster), started 3352)>\n",
      "<Thread(Thread-11 (cpu_waster), started 9220)>\n",
      "<Thread(Thread-12 (cpu_waster), started 12128)>\n",
      "<Thread(Thread-13 (cpu_waster), started 4492)>\n",
      "<Thread(Thread-14 (cpu_waster), started 5744)>\n",
      "<Thread(Thread-15 (cpu_waster), started 10764)>\n",
      "<Thread(Thread-16 (cpu_waster), started 6212)>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import threading\n",
    "\n",
    "# a simple function that wastes CPU cycles forever\n",
    "def cpu_waster():\n",
    "    while True:\n",
    "        pass\n",
    "\n",
    "# display information about this process\n",
    "print('\\n  Process ID: ', os.getpid())\n",
    "print('Thread Count: ', threading.active_count())\n",
    "for thread in threading.enumerate():\n",
    "    print(thread)\n",
    "\n",
    "print('\\nStarting 12 CPU Wasters...')\n",
    "for i in range(12):\n",
    "    threading.Thread(target=cpu_waster).start()\n",
    "\n",
    "# display information about this process\n",
    "print('\\n  Process ID: ', os.getpid())\n",
    "print('Thread Count: ', threading.active_count())\n",
    "for thread in threading.enumerate():\n",
    "    print(thread)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b29e220",
   "metadata": {},
   "source": [
    "### multiprocessing module\n",
    "* for true parallel programming in python, we need to use multiprocessing rather than mutlithreading\n",
    "* to use multiprocessing, we do the following from multithreads\n",
    "  + import multiprocessing \n",
    "  + include all code inside __main__\n",
    "  + replace \n",
    "  ```python\n",
    "  threading.Thread(target=cpu_waster).start()\n",
    "  ```\n",
    "  to \n",
    "  ```python\n",
    "  import multiprocessing as mp\n",
    "  if __name__ == \"__main__\":\n",
    "    for i in range(12):\n",
    "        mp.Process(target=cpu_waster).start()\n",
    "    \n",
    "    for thread in threading.enumerate():\n",
    "        print(thread)\n",
    "  ``` \n",
    "* we need to include the mp process code inside main using the if statement because\n",
    "  + mp.Process command will load the entire script to find out cpu_waster function and other dependencies\n",
    "  + basically, each process will run the script. if we don't include the if condition that only main module can spawn new processes, the child processes will continue to spwan their child processes until the system crashes          \n",
    "* The entire code snippet is attached in the following cell (if we don't include if conditions, line 22 will run forever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ea16ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Threads that waste CPU cycles \"\"\"\n",
    "\n",
    "import os\n",
    "import threading\n",
    "import multiprocessing as mp\n",
    "\n",
    "# a simple function that wastes CPU cycles forever\n",
    "def cpu_waster():\n",
    "    while True:\n",
    "        pass\n",
    "\n",
    "print('Hi! My name is', __name__)\n",
    "if __name__ == '__main__':\n",
    "    # display information about this process\n",
    "    print('\\n  Process ID: ', os.getpid())\n",
    "    print('Thread Count: ', threading.active_count())\n",
    "    for thread in threading.enumerate():\n",
    "        print(thread)\n",
    "\n",
    "    print('\\nStarting 12 CPU Wasters...')\n",
    "    for i in range(12):\n",
    "        mp.Process(target=cpu_waster).start()\n",
    "\n",
    "    # display information about this process\n",
    "    print('\\n  Process ID: ', os.getpid())\n",
    "    print('Thread Count: ', threading.active_count())\n",
    "    for thread in threading.enumerate():\n",
    "        print(thread)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dfd075",
   "metadata": {},
   "source": [
    "### Scheduler\n",
    "* Operating system function that assigns processes and threads to run on available CPUs\n",
    "* scheduler makes it possible for multiple programs to run concurrently on a single processor\n",
    "* when a process is created and ready to run, it gets loaded into memory and placed in the ready queue\n",
    "* scheduler gets through the ready processes so they get a chance to execute on the processor\n",
    "* if there are multiple processors, OS will schedule processes to run on each of them to make the most use of additional resources\n",
    "* the following are some use cases that scheduler will do to processes:\n",
    "  + a process will run until it finishes, and scheduler will assign another process on that processor\n",
    "  + a process might get blocked and have to wait for an I/O event, which will go to a separate I/O waiting queue so another process can run\n",
    "  + scheduler might determine that a process has spent its fair share of time on the processor, and swap it out for another process from the ready queue, which is called a context switch. In a context switch:\n",
    "    + OS has to save the state or context of the process or thread that was running to resume them later\n",
    "    + OS has to load the context of the new process or thread to run\n",
    "    + context switch is not instaneous. it takes time to save and restore the registers and memory state, scheduler needs a strategy for how frequently it switches between processes.\n",
    "* scheduling algorithms\n",
    "  + first come, first served\n",
    "  + shortest job next\n",
    "  + priority\n",
    "  + shortest remaining time\n",
    "  + round robin\n",
    "  + multiple-level queues\n",
    "  + some of these algorithms are preemptive\n",
    "    + meaning that lower priority processes will be paused or stopped when a high priority process enters the ready state.\n",
    "    + non-preemptive algorithms allow a process to run once it is in running state, it is allowed to run for its alloted time\n",
    "* scheduling goals\n",
    "  + which algorithm to choose depends on the scheduling goals and different algorithms will be used by different OS\n",
    "    + max throughput\n",
    "    + max fairness\n",
    "    + min wait time\n",
    "    + min latency\n",
    "  + your program should not rely on expected order of how multiple processes/threads will run\n",
    "  + your program should not rely on that equal amount of time will be assigned to each process/thread    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6022fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Two threads chopping vegetables \"\"\"\n",
    "\n",
    "import threading\n",
    "import time\n",
    "\n",
    "chopping = True\n",
    "\n",
    "def vegetable_chopper():\n",
    "    name = threading.current_thread().getName()\n",
    "    \n",
    "    # set up local variable to count how many times the while loop executes\n",
    "    vegetable_count = 0\n",
    "    while chopping:\n",
    "        print(name, 'chopped a vegetable!')\n",
    "        vegetable_count += 1\n",
    "    print(name, 'chopped', vegetable_count, 'vegetables.')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    threading.Thread(target=vegetable_chopper, name='Barron').start()\n",
    "    threading.Thread(target=vegetable_chopper, name='Olivia').start()\n",
    "\n",
    "    time.sleep(1)    # chop vegetables for 1 second\n",
    "    chopping = False # stop both threads from chopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683a3a9a",
   "metadata": {},
   "source": [
    "The above code shows that\n",
    "* it is unpredictable which thread will execute for how many times in the while loop\n",
    "* variable chopping outside vegetable_chopper did control the while loop inside the function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db04897a",
   "metadata": {},
   "source": [
    "### thread lifecycle\n",
    "when a program or process starts, it will start as a single thread (main thread)\n",
    "* main thread can start or spawn additional child threads as part of the same process, but execute independently to do other tasks\n",
    "* child threads can spawn their child threads. When they finish the executing, they notify their parent threads and terminate\n",
    "* main thread is usually the last thread to finish execution\n",
    "* four states of a thread\n",
    "  + new state \n",
    "    + when a new thread is spawned/created\n",
    "    + the thread doesn't run and doesn't take any CPU resources\n",
    "    + when creating the thread, a function is assigned to it for it to execute\n",
    "    + some programming language requires to start a thread after creating it so that it will go to runnable state\n",
    "  + runnable state\n",
    "    + OS can schedule the thread to execute\n",
    "    + through context switches, the thread can swap with a thread to go on one of the availabe processors\n",
    "  + blocked\n",
    "    + when a thread needs to wait for an event to occur, such as an external input or a timer, it goes to block state\n",
    "    + thread will not use any CPU resources\n",
    "    + OS will resume the thread by putting it on runnable state when the event it waits for occurs\n",
    "    + when a thread needs to wait for other threads (e.g. its child threads) to complete their jobs, we use join()\n",
    "      + wait until another thread completes its execution\n",
    "      + when join() is called, the current thread goes to block state and wait for other thread's job is done\n",
    "  + terminated \n",
    "    + when the thread finishes execution, it will notify its parent thread and goes to terminated state\n",
    "    + when a thread is abnormally aborted also goes to terminated state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f415e8fb",
   "metadata": {},
   "source": [
    "### code example\n",
    "In the next cell, the code is to demonstrate the difference life cycle stage of threads\n",
    "* Barron is the main thread, it spawn the child thread, Olivia\n",
    "* Olivia thread is created by calling the __init__() method of Thread class when ChefOlivia is instantiated by main thread\n",
    "* Olivia thread start (in runnable state) when main thread calls its start() method\n",
    "* main thread waits for olivia thread by calling olivia's join() method from within the main thread\n",
    "  + this block main thread's execution until olivia thread is terminated\n",
    "* after olivia thread is done, main thread resumes the execution and finishes\n",
    "* we can check if a thread is alive by calling its is_alive() method\n",
    "  + when a thread is created, but not runnable, it is not alive\n",
    "  + when a thread is in runnable state, even if it is sleep, it is alive\n",
    "  + when a thread is terminated,it is not alive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8add6e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Two threads cooking soup \"\"\"\n",
    "\n",
    "import threading\n",
    "import time\n",
    "\n",
    "class ChefOlivia(threading.Thread):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def run(self):\n",
    "        print('Olivia started & waiting for sausage to thaw...')\n",
    "        time.sleep(3)\n",
    "        print('Olivia is done cutting sausage.')\n",
    "\n",
    "# main thread\n",
    "if __name__ == '__main__':\n",
    "    print(\"Barron started & requesting Olivia's help.\")\n",
    "    olivia = ChefOlivia()\n",
    "    print('  Olivia alive?:', olivia.is_alive())\n",
    "\n",
    "    print('Barron tells Olivia to start.')\n",
    "    olivia.start()\n",
    "    print('  Olivia alive?:', olivia.is_alive())\n",
    "\n",
    "    print('Barron continues cooking soup.')\n",
    "    time.sleep(0.5)\n",
    "    print('  Olivia alive?:', olivia.is_alive())\n",
    "\n",
    "    print('Barron patiently waits for Olivia to finish and join...')\n",
    "    olivia.join()\n",
    "    print('  Olivia alive?:', olivia.is_alive())\n",
    "\n",
    "    print('Barron and Olivia are both done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de5accb",
   "metadata": {},
   "source": [
    "### Two ways to create threads in python\n",
    "* create python threads with classes that inherits Thread class and overwrite its __init__() and run() methods\n",
    "  + you should only override these two methods\n",
    "  + you need to call the super().__init__() in the init method\n",
    "```python\n",
    "class MyThreadClass(threading.Thread):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def run(self):\n",
    "        print('Olivia started & waiting for sausage to thaw...')\n",
    "        time.sleep(3)\n",
    "        print('Olivia is done cutting sausage.')\n",
    "        \n",
    "olivia = ChefOlivia()\n",
    "olivia.start()\n",
    "```\n",
    "\n",
    "* direct instantiate a Thread object and define the target as the function to run\n",
    "```python\n",
    "threading.Thread(target=vegetable_chopper, name='Barron').start()\n",
    "```\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5db9df",
   "metadata": {},
   "source": [
    "### Daemon threads\n",
    "* Garbage Collector\n",
    "  * automatic memory management running in the background\n",
    "  * reclaim memory no longer in use by program\n",
    "* if a main thread spawn a child thread running in the background, when the main thread finishes, it can not exit because it has child threads still executing\n",
    "  + to solve this problem, we can make the child thread as a daemon (background) thread\n",
    "    + a daemon thread will not prevent a program/process from terminating if it is still running\n",
    "    + by default, threads are created as non-daemon. you need to explicitly turn a thread to a daemon thread\n",
    "    + a daemon thread is called detached from the main thread, it will abruptly stop when main thread exits\n",
    "      + make sure daemon thread will not have negative impacts when it is prematurely exits\n",
    "* the following cell shows a daemon thread code example\n",
    "  + new threads will inherit daemon status from their parent\n",
    "  + main thread is a normal thread, therefore, child threads spawned from main are normal threads\n",
    "  + you set up the thread's daemon status (as shown in line 14 of the code) before staring the thread\n",
    "  + when program ends, remaining daemon threads are abandoned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82c9cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo of daemon threads\n",
    "\"\"\" Barron finishes cooking while Olivia cleans \"\"\"\n",
    "\n",
    "import threading\n",
    "import time\n",
    "\n",
    "def kitchen_cleaner():\n",
    "    while True:\n",
    "        print('Olivia cleaned the kitchen.')\n",
    "        time.sleep(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    olivia = threading.Thread(target=kitchen_cleaner)\n",
    "    olivia.daemon = True\n",
    "    olivia.start()\n",
    "\n",
    "    print('Barron is cooking...')\n",
    "    time.sleep(0.6)\n",
    "    print('Barron is cooking...')\n",
    "    time.sleep(0.6)\n",
    "    print('Barron is cooking...')\n",
    "    time.sleep(0.6)\n",
    "    print('Barron is done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a15b79",
   "metadata": {},
   "source": [
    "### Data Race\n",
    "* two or more concurrent threads access the same memory loaction\n",
    "* at least one thread is modifying it\n",
    "* what happens when a thread updates a value\n",
    "  1. read the value from memory location\n",
    "  2. calculate and modify the value\n",
    "  3. write the calculated value to the memory location\n",
    "  + any thing happens to the value stored in memory between step 1 and 3 and before step 3 creates data race\n",
    "  + a potential case is that two threads reads the memory location a the same time, and based on the read value, one thread updated the value, and then the other updates the value using the outdated value before the first thread's update\n",
    "  + since the timing of thread schedule is not predictable, the result value in memory is not predictable and sometimes are incorrect. especially when there are a lot of updates happens\n",
    "* the best way to prevent this is to pay attention whenever two or more threads access the same resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b577f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstration of data race\n",
    "# two threads are writing to the same varialbe (garlic_count) 1 million times\n",
    "# this creates unpredictable, incosistent results in variable value due to data race\n",
    "# notice that even though there is only one increment statement, the program will need\n",
    "# to read, calculate and then write the updated garlic_count value (the three actions are not atomic)\n",
    "\"\"\" Two shoppers adding items to a shared notepad \"\"\"\n",
    "\n",
    "import threading\n",
    "\n",
    "garlic_count = 0\n",
    "\n",
    "def shopper():\n",
    "    global garlic_count\n",
    "    for i in range(10_000_000):\n",
    "        garlic_count += 1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    barron = threading.Thread(target=shopper)\n",
    "    olivia = threading.Thread(target=shopper)\n",
    "    barron.start()\n",
    "    olivia.start()\n",
    "    barron.join()\n",
    "    olivia.join()\n",
    "    print('We should buy', garlic_count, 'garlic.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dd84eb",
   "metadata": {},
   "source": [
    "### critical section and mutex(lock)\n",
    "* critical section\n",
    "  * a critical section is a code segment that accesses a shared resource such as a data structrue memory or external device and may not operate correctly when multiple threads access it\n",
    "  * critical section needs to be protected to only allow one thread or process execute on it at a time\n",
    "  * critical section should not be executed by more than one thread or process at a time\n",
    "* mutex (lock)\n",
    "  + mutex (lock) is a mchanism to implement mutual exclusion\n",
    "  + only allow one thread or process to possess at a time\n",
    "  + this limits access to critical section\n",
    "  + when a thread is trying to acquire a lock and find the lock is already token, it will block/wait for it to be available\n",
    "  + the critical sections (protected sections of code) should be as short as possible\n",
    "* atomic operation\n",
    "  + to process to acquire the lock is an atomic operation meaning\n",
    "    + it executes as a single action, relative to other threads\n",
    "    + cannot be interrupted by other concurrent threads\n",
    "* in python, we use the lock object included threading package, as shown in the following cell of the demo code\n",
    "  + the critical section in line 15 is protected by mutex. in line 14, the lock is aquired, and after the incrementation, released.\n",
    "  + note that we only need to protect the shortest part of the code (garlic_count += 1) to make it atomic and protected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e2a926",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Two shoppers adding items to a shared notepad \"\"\"\n",
    "\n",
    "import threading\n",
    "import time\n",
    "\n",
    "garlic_count = 0\n",
    "pencil = threading.Lock()\n",
    "\n",
    "def shopper():\n",
    "    global garlic_count\n",
    "    for i in range(5):\n",
    "        print(threading.current_thread().getName(), 'is thinking.')\n",
    "        time.sleep(0.5)\n",
    "        pencil.acquire()\n",
    "        garlic_count += 1\n",
    "        pencil.release()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    barron = threading.Thread(target=shopper)\n",
    "    olivia = threading.Thread(target=shopper)\n",
    "    barron.start()\n",
    "    olivia.start()\n",
    "    barron.join()\n",
    "    olivia.join()\n",
    "    print('We should buy', garlic_count, 'garlic.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdf77db",
   "metadata": {},
   "source": [
    "### Deadlock\n",
    "* reentrant mutex\n",
    "  * Deadlock: if a thread tries to aquire a lock it already has, then all processes and threads waiting for the lock are unable to continue executing. This is called a deadlock\n",
    "  * When a program needs to lock a mutex multiple times before unlocing it. you should use reentrant mutex lock \n",
    "* a reentrant mutex can be locked multiple times by the same thread\n",
    "* it record the times it has been locked, and it must be unlocked as many times as it was locked before another thread can unlock it\n",
    "* one example: we have a function incrementCounter() that locks mutex, and myFunction() calls that function also use lock. The thread executing myFunction will aquire lock and can unlock it multiple times to release the lock\n",
    "\n",
    "```python\n",
    "def incrementCounter(){\n",
    "    lock()\n",
    "    counter++\n",
    "    unlock()\n",
    "}\n",
    "\n",
    "def myFunction(){\n",
    "    lock()\n",
    "    incrementCounter()\n",
    "    unlock()\n",
    "}\n",
    "```\n",
    "\n",
    "* another use case for reentrant mutex is used by recursive functions that use lock. Therefore, the following are the same\n",
    "  + reentrant mutex\n",
    "  + reentrant lock\n",
    "  + recursive mutex\n",
    "  + recursive lock\n",
    "* python's implementation of reentrant lock is RLock, as shown in the following cell\n",
    "* difference between Lock and RLock in python\n",
    "  + Lock can be released by a different thread than was used to aquire it\n",
    "  + RLock must be released by the same thread that acquired it\n",
    "    + in addition, it must be released the same number of times it was acquired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fad8e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Two shoppers adding garlic and potatoes to a shared notepad \"\"\"\n",
    "\n",
    "import threading\n",
    "\n",
    "garlic_count = 0\n",
    "potato_count = 0\n",
    "pencil = threading.RLock()\n",
    "\n",
    "def add_garlic():\n",
    "    global garlic_count\n",
    "    pencil.acquire()\n",
    "    garlic_count += 1\n",
    "    pencil.release()\n",
    "\n",
    "# add_potato calls add_garlic that repeatedly acquire and release lock\n",
    "    def add_potato():\n",
    "    global potato_count\n",
    "    pencil.acquire()\n",
    "    potato_count += 1\n",
    "    add_garlic()\n",
    "    pencil.release()\n",
    "\n",
    "def shopper():\n",
    "    for i in range(10_000):\n",
    "        add_garlic()\n",
    "        add_potato()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    barron = threading.Thread(target=shopper)\n",
    "    olivia = threading.Thread(target=shopper)\n",
    "    barron.start()\n",
    "    olivia.start()\n",
    "    barron.join()\n",
    "    olivia.join()\n",
    "    print('We should buy', garlic_count, 'garlic.')\n",
    "    print('We should buy', potato_count, 'potatoes.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dcc1d7",
   "metadata": {},
   "source": [
    "### Try Lock\n",
    "* When the thread has other tasks to do, it doesnot have to be blocked and wait for lock. The logic of try lock is:\n",
    "  + it is a non-blocking lock/acquire method for mutex\n",
    "  + try lock do the following:\n",
    "    + If the mutex is available, acquires it and return True\n",
    "    + otherwise, immediately return False so the thread can process other tasks\n",
    "* in python, the non-blocking loc is implemented by setting blocking=False when acquiring lock, which returns a bool\n",
    "  + while waiting for lock, the thread can execute the increment of items_to_add that improves the productivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea01f3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Two shoppers adding items to a shared notepad \"\"\"\n",
    "\n",
    "import threading\n",
    "import time\n",
    "\n",
    "items_on_notepad = 0\n",
    "pencil = threading.Lock()\n",
    "\n",
    "def shopper():\n",
    "    global items_on_notepad\n",
    "    name = threading.current_thread().getName()\n",
    "    items_to_add = 0\n",
    "    while items_on_notepad <= 20:\n",
    "        if items_to_add and pencil.acquire(blocking=False): # add item(s) to shared items_on_notepad\n",
    "            items_on_notepad += items_to_add\n",
    "            print(name, 'added', items_to_add, 'item(s) to notepad.')\n",
    "            items_to_add = 0\n",
    "            time.sleep(0.3) # time spent writing\n",
    "            pencil.release()\n",
    "        else: # look for other things to buy\n",
    "            time.sleep(0.1) # time spent searching\n",
    "            items_to_add += 1\n",
    "            print(name, 'found something else to buy.')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    barron = threading.Thread(target=shopper, name='Barron')\n",
    "    olivia = threading.Thread(target=shopper, name='Olivia')\n",
    "    start_time = time.perf_counter()\n",
    "    barron.start()\n",
    "    olivia.start()\n",
    "    barron.join()\n",
    "    olivia.join()\n",
    "    elapsed_time = time.perf_counter() - start_time\n",
    "    print('Elapsed Time: {:.2f} seconds'.format(elapsed_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4eac66",
   "metadata": {},
   "source": [
    "### reader-writer lock\n",
    "* commonly used lock locks all threads to access the critical sections, which is not efficient since threads only read from the section should be safe and shouldn't be blocked\n",
    "* a reader-writer lock or shared mutex can be locked in two ways\n",
    "  + locked in a shared read mode that allows multiple threads that only need simultaneous reads to lock it\n",
    "  + or exclusive write that only allow one thread at a time to write to the resource\n",
    "  + when switching between these two modes, a thread need to wait\n",
    "* it is better to use reader-writer lock when there are lot more read threads than write threads \n",
    "* in the following cell of code\n",
    "  + RWLockFair give equal priorities to read and write\n",
    "  + gen_rlock()- generates a reader lock object\n",
    "  + gen_wlock()- generates a writer lock object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecd9e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Several users reading a calendar, but only a few users updating it \"\"\"\n",
    "\n",
    "import threading\n",
    "from readerwriterlock import rwlock\n",
    "\n",
    "WEEKDAYS = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "today = 0\n",
    "\n",
    "marker = rwlock.RWLockFair()\n",
    "\n",
    "def calendar_reader(id_number):\n",
    "    global today\n",
    "    read_marker = marker.gen_rlock()\n",
    "    name = 'Reader-' + str(id_number)\n",
    "    while today < len(WEEKDAYS)-1:\n",
    "        read_marker.acquire()\n",
    "        print(name, 'sees that today is', WEEKDAYS[today], '-read count:', read_marker.c_rw_lock.v_read_count)\n",
    "        read_marker.release()\n",
    "\n",
    "def calendar_writer(id_number):\n",
    "    global today\n",
    "    write_marker = marker.gen_wlock()\n",
    "    name = 'Writer-' + str(id_number)\n",
    "    while today < len(WEEKDAYS)-1:\n",
    "        write_marker.acquire()\n",
    "        today = (today + 1) % 7\n",
    "        print(name, 'updated date to ', WEEKDAYS[today])\n",
    "        write_marker.release()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # create ten reader threads\n",
    "    for i in range(10):\n",
    "        threading.Thread(target=calendar_reader, args=(i,)).start()\n",
    "    # ...but only two writer threads\n",
    "    for i in range(2):\n",
    "        threading.Thread(target=calendar_writer, args=(i,)).start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9cb1a9",
   "metadata": {},
   "source": [
    "### Deaklock\n",
    "* in multiple threads with multiple locks system, deaklock occurs when each thread is waiting for another thread to tack action. For example, to access a resource, each thread needs to acquire two locks. If each of the two threads acquires one lock, and then waiting for the other lock, then neigher of these two threads can make progress and they kare in deadlock.\n",
    "* this is a common challenge when using mutex to protect critical sections of the code.\n",
    "* we want program to be free of deadlock to guarantee liveness\n",
    "* liveness:\n",
    "  + properties that require a system to make progress\n",
    "* deadlock sometimes happens, sometimes not. It is diffciult to identify\n",
    "* one solution is to keep a priority list of the locks, and follow that order to acquire locks for all threads.\n",
    "   + ensure locks are always taken in the sqame order by any thread\n",
    "* another solution is to use lock timeout\n",
    "  + put a timeout on lock attempts\n",
    "  + if a thread can not acquire all locks within the time limit:\n",
    "    + back up and free all locks taken\n",
    "    + wait for a random amount of time\n",
    "    + try again\n",
    "* code in the following cell implements three threads acquiring locks in a consistent order with priorities a > b > c    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa18920",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Three philosophers, thinking and eating sushi \"\"\"\n",
    "\n",
    "import threading\n",
    "\n",
    "chopstick_a = threading.Lock()\n",
    "chopstick_b = threading.Lock()\n",
    "chopstick_c = threading.Lock()\n",
    "sushi_count = 500\n",
    "\n",
    "def philosopher(name, first_chopstick, second_chopstick):\n",
    "    global sushi_count\n",
    "    while sushi_count > 0: # eat sushi until it's all gone\n",
    "        first_chopstick.acquire()\n",
    "        second_chopstick.acquire()\n",
    "\n",
    "        if sushi_count > 0:\n",
    "            sushi_count -= 1\n",
    "            print(name, 'took a piece! Sushi remaining:', sushi_count)\n",
    "\n",
    "        second_chopstick.release()\n",
    "        first_chopstick.release()\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    threading.Thread(target=philosopher, args=('Barron', chopstick_a, chopstick_b)).start()\n",
    "    threading.Thread(target=philosopher, args=('Olivia', chopstick_b, chopstick_c)).start()\n",
    "    threading.Thread(target=philosopher, args=('Steve', chopstick_a, chopstick_c)).start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56635952",
   "metadata": {},
   "source": [
    "### Abandoned lock\n",
    "* when a program/thread acquires a lock and then terminates because unexpected reasons, it may not automatically release the lock\n",
    "* other threads waiting for the lock will never acquire the lock\n",
    "* the solution is to put the critical section access code in a try block and put the lock release code in a finally section\n",
    "* the example code is shown in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa78e461",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Three philosophers, thinking and eating sushi \"\"\"\n",
    "\n",
    "import threading\n",
    "\n",
    "chopstick_a = threading.Lock()\n",
    "chopstick_b = threading.Lock()\n",
    "chopstick_c = threading.Lock()\n",
    "sushi_count = 500\n",
    "some_lock = threading.Lock()\n",
    "\n",
    "some_lock.acquire()\n",
    "# try:\n",
    "#     # do something...\n",
    "# finally:\n",
    "#     some_lock.release()\n",
    "# \n",
    "# with some_lock:\n",
    "#     #do something...\n",
    "\n",
    "def philosopher(name, first_chopstick, second_chopstick):\n",
    "    global sushi_count\n",
    "    while sushi_count > 0: # eat sushi until it's all gone\n",
    "        first_chopstick.acquire()\n",
    "        second_chopstick.acquire()\n",
    "        try:\n",
    "            if sushi_count > 0:\n",
    "                sushi_count -= 1\n",
    "                print(name, 'took a piece! Sushi remaining:', sushi_count)\n",
    "            if sushi_count == 10:\n",
    "                print(1/0)\n",
    "        finally:\n",
    "            second_chopstick.release()\n",
    "            first_chopstick.release()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    threading.Thread(target=philosopher, args=('Barron', chopstick_a, chopstick_b)).start()\n",
    "    threading.Thread(target=philosopher, args=('Olivia', chopstick_b, chopstick_c)).start()\n",
    "    threading.Thread(target=philosopher, args=('Steve', chopstick_a, chopstick_c)).start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de1da2b",
   "metadata": {},
   "source": [
    "### Abandoned lock using context manager\n",
    "* we can utilize python context manager to manage the lock release, as shown in the following cell\n",
    "* as shown in line 13 and 14, the context manager manages the lock acquire and release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4632ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Three philosophers, thinking and eating sushi \"\"\"\n",
    "\n",
    "import threading\n",
    "\n",
    "chopstick_a = threading.Lock()\n",
    "chopstick_b = threading.Lock()\n",
    "chopstick_c = threading.Lock()\n",
    "sushi_count = 500\n",
    "\n",
    "def philosopher(name, first_chopstick, second_chopstick):\n",
    "    global sushi_count\n",
    "    while sushi_count > 0: # eat sushi until it's all gone\n",
    "        with first_chopstick:\n",
    "            with second_chopstick:\n",
    "                if sushi_count > 0:\n",
    "                    sushi_count -= 1\n",
    "                    print(name, 'took a piece! Sushi remaining:', sushi_count)\n",
    "\n",
    "                if sushi_count == 10:\n",
    "                    print(1/0)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    threading.Thread(target=philosopher, args=('Barron', chopstick_a, chopstick_b)).start()\n",
    "    threading.Thread(target=philosopher, args=('Olivia', chopstick_b, chopstick_c)).start()\n",
    "    threading.Thread(target=philosopher, args=('Steve', chopstick_a, chopstick_c)).start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf63f8c",
   "metadata": {},
   "source": [
    "### Starvation\n",
    "* when a thread or process is perpetually denied the resources it needs. It can not access the resources it needs\n",
    "* starvation happens when \n",
    "  + threads have different priorities compete for resources, and low priority threads will never access resources\n",
    "  + there are too many threads competing (as shown in the following cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1020f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Three philosophers, thinking and eating sushi \"\"\"\n",
    "\n",
    "import threading\n",
    "\n",
    "chopstick_a = threading.Lock()\n",
    "chopstick_b = threading.Lock()\n",
    "chopstick_c = threading.Lock()\n",
    "sushi_count = 5000\n",
    "\n",
    "def philosopher(name, first_chopstick, second_chopstick):\n",
    "    global sushi_count\n",
    "    sushi_eaten = 0\n",
    "    while sushi_count > 0: # eat sushi until it's all gone\n",
    "        with first_chopstick:\n",
    "            with second_chopstick:\n",
    "                if sushi_count > 0:\n",
    "                    sushi_count -= 1\n",
    "                    sushi_eaten += 1\n",
    "                    print(name, 'took a piece! Sushi remaining:', sushi_count)\n",
    "    print(name, 'took', sushi_eaten, 'pieces')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for thread in range(50):\n",
    "        threading.Thread(target=philosopher, args=('Barron', chopstick_a, chopstick_b)).start()\n",
    "        threading.Thread(target=philosopher, args=('Olivia', chopstick_a, chopstick_b)).start()\n",
    "        threading.Thread(target=philosopher, args=('Steve', chopstick_a, chopstick_b)).start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fd5796",
   "metadata": {},
   "source": [
    "### Livelock\n",
    "* multiple theads or processors are actively responding to each other to resolve conflict, but that prevents them from making progress\n",
    "* no threads will make progress because they give up their locks.\n",
    "* to resolve that, make sure only one thread is taking action chosen by priority or other mechanisms like random selection\n",
    "* different from deadlock, threads in livelock are actively executing without useful progress.\n",
    "* in the following cell, the livelock is resolved by assigning a random number of seconds to sleep once a thread release its first lock once the second lock is not available. This gives other threads time to acquire both locks before it acquire its first lock again immediately after it release the frist lock\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26cde51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Three philosophers, thinking and eating sushi \"\"\"\n",
    "\n",
    "import threading\n",
    "import time\n",
    "from random import random\n",
    "\n",
    "chopstick_a = threading.Lock()\n",
    "chopstick_b = threading.Lock()\n",
    "chopstick_c = threading.Lock()\n",
    "sushi_count = 500\n",
    "\n",
    "def philosopher(name, first_chopstick, second_chopstick):\n",
    "    global sushi_count\n",
    "    while sushi_count > 0: # eat sushi until it's all gone\n",
    "        first_chopstick.acquire()\n",
    "        if not second_chopstick.acquire(blocking=False):\n",
    "            print(name, 'released their first chopstick.')\n",
    "            first_chopstick.release()\n",
    "            time.sleep(random()/10)\n",
    "        else:\n",
    "            try:\n",
    "                if sushi_count > 0:\n",
    "                    sushi_count -= 1\n",
    "                    print(name, 'took a piece! Sushi remaining:', sushi_count)\n",
    "            finally:\n",
    "                second_chopstick.release()\n",
    "                first_chopstick.release()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    threading.Thread(target=philosopher, args=('Barron', chopstick_a, chopstick_b)).start()\n",
    "    threading.Thread(target=philosopher, args=('Olivia', chopstick_b, chopstick_c)).start()\n",
    "    threading.Thread(target=philosopher, args=('Steve', chopstick_c, chopstick_a)).start()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
